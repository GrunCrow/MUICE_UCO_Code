# TFM: Application of Deep Learning techniques in the Classification of Bird Audio for Environmental Monitoring in Doñana

## Abstract

Passive acoustic monitoring through the use of devices such as automatic audio recorders has emerged as a fundamental tool in the conservation and management of natural ecosystems. However, this practice presents a significant challenge given it generates a large volume of data that does not have human supervision. In order to obtain valid information for ecoacoustics studies, the main bottleneck now is to manage large datasets of acoustic recordings for identifying species of interest.  Automated species detection methods using deep learning techniques are paramount for this. In this communication, we present a multi-stage process for automatic analysis of bird recordings from Doñana National Park (SW Spain) obtained through AudioMoths thanks to the BIRDeep project. Although existing Deep Learning models such as BirdNET have shown success in bird identification in other study systems, they did not present satisfactory results for the most abundant species of Doñana, likely due to inadequate training on Doñana’s specific data and its bias on focal sounds, rather than entire soundscapes. Consequently, we annotated about 600 minutes of audio data at three different habitats  and trained our own model.  By using the Mel spectrogram as a graphical representation of bird audio data, we show how this technique can be leveraged to apply image processing methods and computer vision in the analysis of acoustic data analysis. For this, it is critical the availability of labeled, high-quality datasets. In conclusion, our advances show that general-purpose tools may not always be the best solution in deep learning and ecoacoustics, emphasizing the importance of adapting these tools to the specific problem being addressed. By fine- tuning deep learning models and techniques to the unique characteristics of ecoacoustic data from a specific context, researchers can improve the accuracy and efficiency of biodiversity monitoring efforts.

## Repositorio

Para acceder al contenido del código con el que se realizaron las experimentaciones del TFM antes descrito puedes acceder al repositorio [BIRDeep_NeuralNetworks](https://github.com/GrunCrow/BIRDeep_NeuralNetworks)

